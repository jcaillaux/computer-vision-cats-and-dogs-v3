# ğŸ—ï¸ Exercices Atelier MLOps

## Objectif

Ajouter progressivement des mÃ©triques de monitoring Ã  l'application de classification d'images.

---

## ğŸ“Š Exercice 1 : MÃ©trique Latence d'InfÃ©rence (Jour 1-2)

### Objectif
Monitorer le temps de rÃ©ponse des prÃ©dictions.

### Fichiers Ã  Modifier

#### 1. `src/monitoring/prometheus_metrics.py`

**Ajouter** :
```python
# TODO: CrÃ©er mÃ©trique histogram pour latence
inference_time_histogram = Histogram(
    'cv_inference_time_seconds',
    'Temps d\'infÃ©rence en secondes'
)

def track_inference_time(inference_time_ms: float):
    """Enregistre le temps d'infÃ©rence"""
    inference_time_histogram.observe(inference_time_ms / 1000)
```

#### 2. `src/routes.py`

Dans la fonction `predict()`, **ajouter** :
```python
# TODO: Mesurer et tracker le temps d'infÃ©rence
start_time = time.time()
# ... code de prÃ©diction ...
inference_time_ms = (time.time() - start_time) * 1000
track_inference_time(inference_time_ms)
```

#### 3. `monitoring/prometheus/rules/alerts.yml`

**Ajouter** :
```yaml
  - alert: alert_high_latency
    expr: rate(cv_inference_time_seconds_sum[5m]) / rate(cv_inference_time_seconds_count[5m]) > 2
    for: 2m
    labels:
      severity: warning
    annotations:
      summary: "Latence Ã©levÃ©e dÃ©tectÃ©e"
      description: "Latence moyenne > 2s pendant 2 minutes"
```

#### 4. `monitoring/grafana/provisioning/alerting/cv-alerts.yml`

**Ajouter l'alerte** (voir exemple dans le dashboard actuel)

### DÃ©ployer
```bash
git add .
git commit -m "feat: Add inference_time metric"
git push origin main
```

### VÃ©rifier

1. Grafana â†’ Explorer â†’ RequÃªte : `cv_inference_time_seconds`
2. Faire 10 prÃ©dictions sur l'API
3. VÃ©rifier que la mÃ©trique s'affiche
4. CrÃ©er un panel Grafana pour afficher la latence moyenne

---

## ğŸ“ Exercice 2 : MÃ©trique Feedback Utilisateur (Jour 3)

### Objectif
Tracker les retours utilisateurs (positifs/nÃ©gatifs).

### Ã€ ImplÃ©menter

1. **MÃ©trique Prometheus** :
```python
feedback_counter = Counter(
    'cv_user_feedback_total',
    'Nombre de feedbacks utilisateurs',
    ['feedback_type']  # 'positive' ou 'negative'
)
```

2. **Route** : Modifier `/feedback` pour appeler `track_feedback()`

3. **Alerte** : Si taux de feedback nÃ©gatif > 50% pendant 10min

4. **Dashboard Grafana** : Panel pie chart pour rÃ©partition positive/negative

---

## ğŸ¨ Exercice 3 : MÃ©triques Custom (Jour 3-4)

Choisir **2 mÃ©triques** parmi :

- Distribution des prÃ©dictions (cats vs dogs)
- Nombre d'utilisateurs uniques
- Taux de prÃ©dictions avec faible confiance (< 60%)
- Nombre de requÃªtes par heure
- Taille moyenne des images uploadÃ©es

### Livrables

1. Code Python (mÃ©triques + routes)
2. Alertes Prometheus
3. Alertes Grafana provisionnÃ©es
4. Dashboard Grafana complet

---

## ğŸ† Bonus (Jour 4)

### Tests AutomatisÃ©s dans CI/CD

Ajouter dans `.github/workflows/deploy.yml` **AVANT** le dÃ©ploiement :
```yaml
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      - run: pip install -r requirements/base.txt -r requirements/dev.txt
      - run: pytest tests/ -v
```

### Dashboard Grafana StylÃ©

- Utiliser des variables
- Ajouter des liens entre panels
- Organiser en rows
- Utiliser des thresholds colorÃ©s
- Ajouter des descriptions

---

## âœ… Checkpoints de Validation

- [ ] MÃ©trique inference_time visible dans Prometheus
- [ ] Alerte high_latency configurÃ©e
- [ ] Dashboard Grafana affiche la latence
- [ ] Notification Discord reÃ§ue en cas d'alerte
- [ ] MÃ©trique feedback_counter fonctionnelle
- [ ] 2 mÃ©triques custom implÃ©mentÃ©es
- [ ] Tests automatisÃ©s dans CI/CD
- [ ] Dashboard final complet et stylÃ©